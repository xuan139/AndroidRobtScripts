from fastapi import FastAPI, Request
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
import base64
import os
import uuid
from dotenv import load_dotenv
import json
import io
import openai
import time
from faster_whisper import WhisperModel
import time
import tempfile
import pyttsx3


from openai import OpenAI
# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

# æ¨èç”¨ç¯å¢ƒå˜é‡è¯»å– API Key
api_key = os.getenv("OPENAI_API_KEY")

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI(api_key=api_key)

last_gpt_reply = None
last_transcript_text = None
last_transcript_language = None
app = FastAPI()

# åŠ  CORS ä¸­é—´ä»¶ï¼Œè§£å†³ 405 é”™è¯¯
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰å‰ç«¯è®¿é—®ï¼Œå¼€å‘æ–¹ä¾¿
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æä¾›é™æ€æ–‡ä»¶
app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/static/js", StaticFiles(directory="static/js"), name="js")
app.mount("/static/css", StaticFiles(directory="static/css"), name="css")
app.mount("/static/db", StaticFiles(directory="static/db"), name="db")
app.mount("/static/images", StaticFiles(directory="static/images"), name="images")
app.mount("/static/uploads", StaticFiles(directory="static/uploads"), name="uploads")
app.mount("/responses", StaticFiles(directory="responses"), name="responses")

def process_gpt_reply(gpt_reply):
    try:
        gpt_reply_dict = json.loads(gpt_reply)
        print("âœ… æˆåŠŸè§£æä¸º JSON")
        return gpt_reply_dict
    except json.JSONDecodeError:
        # print(gpt_reply)
        # åŒ…è£…æˆæ ‡å‡†æ ¼å¼è¿”å›
        return {
            "responses": [{"reply": gpt_reply}],
            "order": [],
            "user_preference": "",
            "note": "",
            "checkout": False
        }



def generate_tts_audio_url(reply_text):
    try:
        print("[INFO] æ­£åœ¨ç”Ÿæˆè¯­éŸ³...")

        # åˆå§‹åŒ–å¼•æ“
        engine = pyttsx3.init()

        # voices = engine.getProperty('voices')
        # for voice in voices:
        #     print(f"Voice ID: {voice.id}, Name: {voice.name}")

        filename = "temp.wav"
        print(f"[INFO] ä¿å­˜è¯­éŸ³åˆ°æ–‡ä»¶: {filename}")
        
        # å°è¯•ä¿å­˜æ–‡ä»¶å¹¶æ•è·å¼‚å¸¸
        engine.save_to_file(reply_text, filename)
        engine.runAndWait()
        
        print("[INFO] è¯­éŸ³åˆæˆä»»åŠ¡å·²å¯åŠ¨")

        if not os.path.exists(filename):
            raise RuntimeError("è¯­éŸ³æ–‡ä»¶æœªæˆåŠŸç”Ÿæˆï¼")
        print("[INFO] è¯­éŸ³æ–‡ä»¶ç”ŸæˆæˆåŠŸ")

        with open(filename, "rb") as f:
            audio_data = f.read()
        print(f"[INFO] è¯»å–éŸ³é¢‘æ–‡ä»¶ï¼Œå¤§å°: {len(audio_data)} å­—èŠ‚")

        audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        print(f"[INFO] Base64 ç¼–ç å®Œæˆï¼Œé•¿åº¦: {len(audio_base64)} å­—ç¬¦")

        os.remove(filename)
        print(f"[INFO] å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {filename}")

        audio_url = f"data:audio/mp3;base64,{audio_base64}"
        print(f"[INFO] ç”Ÿæˆçš„éŸ³é¢‘URLå‰50å­—ç¬¦: {audio_url[:50]}...")

        return audio_url

    except Exception as e:
        print(f"[ERROR] å‘ç”Ÿé”™è¯¯: {e}")
        return None

def split_text_by_word_limit(text, word_limit=20):
    words = text.split()
    segments = []
    
    # æŒ‰ç…§æ¯20ä¸ªå•è¯è¿›è¡Œåˆ†æ®µ
    for i in range(0, len(words), word_limit):
        segments.append(' '.join(words[i:i + word_limit]))
    
    return segments

@app.on_event("startup")
async def load_system_prompt():
    global system_prompt
    with open("system_prompt.txt", "r", encoding="utf-8") as f:
        system_prompt = f.read()


@app.get("/", response_class=HTMLResponse)
def read_index():
    with open("static/index.html", "r", encoding="utf-8") as f:
        return HTMLResponse(content=f.read(), status_code=200)


@app.get("/backend", response_class=HTMLResponse)
def read_backend():
    with open("static/backend.html", "r", encoding="utf-8") as f:
        return HTMLResponse(content=f.read(), status_code=200)

# ä¸Šä¼ å½•éŸ³ base64
@app.post("/upload-audio-base64")
async def upload_audio_base64(request: Request):
    global last_gpt_reply 
    global last_transcript_text 
    global last_transcript_language 
        # å¦‚æœ last_gpt_reply ä¸º Noneï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²
    last_gpt_reply = last_gpt_reply if last_gpt_reply else ""
    last_transcript_text = last_transcript_text if last_transcript_text else ""    
    last_transcript_language = last_transcript_language if last_transcript_language else ""
    # ---- å®‰å…¨è¯»å– last_transcript ----

    print("ä¸Šä¸€æ¬¡è¯­è¨€ï¼š", last_transcript_language)
    print("ä¸Šä¸€æ¬¡æ–‡æœ¬ï¼š", last_transcript_text)
    reply_text = ""

    data = await request.json()
    base64_audio = data.get("file")

    if not base64_audio:
        return JSONResponse(content={"error": "No file provided"}, status_code=400)

    # å¤„ç†ä¸åŒç±»å‹çš„éŸ³é¢‘æ ¼å¼å‰ç¼€
    if base64_audio.startswith("data:audio/wav;base64,"):
        base64_audio = base64_audio.replace("data:audio/wav;base64,", "")
    elif base64_audio.startswith("data:audio/mp3;base64,"):
        base64_audio = base64_audio.replace("data:audio/mp3;base64,", "")
    elif base64_audio.startswith("data:audio/ogg;base64,"):
        base64_audio = base64_audio.replace("data:audio/ogg;base64,", "")
    else:
        return JSONResponse(content={"error": "Unsupported audio format"}, status_code=400)

    # è§£ç  base64 æ•°æ®
    try:
        audio_data = base64.b64decode(base64_audio)
    except Exception as e:
        return JSONResponse(content={"error": f"Base64 decoding error: {str(e)}"}, status_code=400)

    audio_file = io.BytesIO(audio_data)
    audio_file.name = 'audio.mp3'  # è®¾ç½®æ–‡ä»¶å

    start = time.perf_counter()
    # try:
    #     transcript = client.audio.transcriptions.create(
    #         model="whisper-1",
    #         file=audio_file,
    #         response_format="verbose_json"
    #     )

    #     end = time.perf_counter()
    #     print(f"ğŸ•’ Whisper èªéŸ³è­˜åˆ¥è€—æ™‚: {end - start:.4f} ç§’")

    #     print("æ–°æ–‡æœ¬", transcript.text)
    #     print("æ–°è¯­è¨€" , transcript.language)  
    # except Exception as e:
    #     return JSONResponse(content={"error": f"Whisper API error: {str(e)}"}, status_code=500)


        # ä½¿ç”¨ tiny æ¨¡å‹ï¼ˆé€Ÿåº¦æœ€å¿«ï¼‰ï¼Œå¯é¸ cpu æˆ– cuda
    model = WhisperModel("small", device="cuda", compute_type="float16") # æˆ– device="cuda" ä½¿ç”¨ GPU

    start_time = time.time()

    # å°† BytesIO å†™å…¥ä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as tmp:
        tmp.write(audio_data)
        tmp.flush()
        audio_path = tmp.name  # ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        # ç„¶åä¼ ç»™ transcribe
        segments, info = model.transcribe(audio_path)


    segments, info = model.transcribe(audio_path)
    segments = list(segments)  # ğŸ”¥ é—œéµï¼šmaterialize generator
    end_time = time.time()

    print(f"èªè¨€åµæ¸¬çµæœï¼š{info.language}")
    for segment in segments:
        print(f"[{segment.start:.2f}s - {segment.end:.2f}s]: {segment.text}")

    full_text = " ".join([segment.text for segment in segments])
    print("å®Œæ•´æ–‡æœ¬å…§å®¹ï¼š", full_text)
    print(f"è½‰éŒ„èŠ±è²»æ™‚é–“ï¼š{end_time - start_time:.2f} ç§’")

    print("last_gpt_reply",last_gpt_reply)
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "assistant", "content": last_transcript_text},
        {"role": "assistant", "content": last_transcript_language},
        {"role": "assistant", "content": last_gpt_reply},
        {"role": "user", "content": full_text}
    ]

    start = time.perf_counter()

    chat_response = client.chat.completions.create(
        model="gpt-4o",  
        messages=messages
    )

    end = time.perf_counter()
    print(f"ğŸ•’ ChatGPT å›æ‡‰è€—æ™‚: {end - start:.4f} ç§’")
 
    # ç¤ºä¾‹ç”¨æ³•
    gpt_reply = chat_response.choices[0].message.content 

    gpt_reply_data = process_gpt_reply(gpt_reply)
       # è·å–å„å­—æ®µå€¼
    responses = gpt_reply_data.get("responses", [])
    reply_text = responses[0].get("reply", "") if responses else ""
    # reply_text = "æ”¶åˆ°ä½ çš„éœ€æ±‚"
    print("reply_text",reply_text)

    start = time.perf_counter()
    chat_response_tts = client.audio.speech.create(
        model="tts-1",
        voice="nova",
        input=reply_text
    )

    end = time.perf_counter()
    print(f"ğŸ•’ ChatGPT tts å›åº”æ—¶é—´: {end - start:.4f} ç§’")

        # è·å– TTS åˆæˆçš„äºŒè¿›åˆ¶éŸ³é¢‘å†…å®¹
    audio_data = chat_response_tts.content  # è·å–äºŒè¿›åˆ¶å†…å®¹
    audio_base64 = base64.b64encode(audio_data).decode('utf-8')
    audio_url = f"data:audio/mp3;base64,{audio_base64}"

    last_gpt_reply = gpt_reply
    # last_transcript = transcript
    # last_transcript_text = transcript.text
    # last_transcript_language = transcript.language
 
    return {
        "transcript": full_text,
        "language": info.language,
        "gpt_reply_data": gpt_reply_data,
        "tts_audio_url": audio_url
    }